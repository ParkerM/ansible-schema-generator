#!/usr/bin/env python

# ansible-schema-generator
#
# Copyright (C) 2017 Pavel Odvody <podvody@redhat.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import ast
import argparse
import json
import logging
import os
import re
import sys
from collections import defaultdict, namedtuple, OrderedDict

import daiquiri
import semver
import yaml


logger = daiquiri.getLogger('ansible-schema')


DOCUMENTATION_KEY = 'DOCUMENTATION'
TITLE_KEYS = ('module',)
IGNORE_KEYS = (('plugin_type',), ('strategy',), ('callback'),)
FREE_FORM_KEYS = (('free_form',),)
COMMAND_MODULES = ('shell', 'command', 'script', 'raw',)
LOG_LEVEL_MAP = {'debug': logging.DEBUG,
                 'warning': logging.WARNING, 'error': logging.ERROR}
LIST_MATCHER = re.compile(r'^\W*[Ll]ist')
DICT_MATCHER = re.compile(r'\W*[Aa]? ?[Dd]ictionary')


ANSIBLE_NUMBER_LIKE = {'oneOf': [{'type': 'integer'}, {'type': 'string'}]}
ANSIBLE_TRUTH_LIKE = {'oneOf': [{'type': 'boolean'},
                                {'enum': [0, 1], 'type': 'integer'},
                                {'enum': ['yes',
                                          'no',
                                          'Yes',
                                          'No',
                                          'YES',
                                          'NO',
                                          'on',
                                          'off',
                                          'On',
                                          'Off',
                                          'ON',
                                          'OFF',
                                          '1',
                                          '0',
                                          'true',
                                          'false',
                                          'True',
                                          'False'
                                          'TRUE',
                                          'FALSE'], 'type': 'string'}]}


Property = namedtuple('Property', 'name description type required aliases choices')
TypeFix = namedtuple('TypeFix', 'module option type version')


def organize_type_fixes(typefixes):
    fixes = defaultdict(dict)
    for tf in typefixes:
        fixes[tf.module][tf.option] = (tf.version, tf.type)
    return fixes


__typefixes = organize_type_fixes([
    TypeFix('azure_rm_deployment', 'parameters', {'type': 'object'}, '<2.6.0')
])

def apply_fix(fix, default, version):
    version_match, alt_type = fix
    if semver.match(version, version_match):
        return alt_type
    return default


def get_definitions():
    matcher = re.compile('^ANSIBLE_([A-Z]*)_LIKE$')
    g = globals()
    defs = {}
    for n, v in g.iteritems():
        m = matcher.match(n)
        if m:
            name = m.group(1).lower()
            defs['ansible_' + name] = v
    return defs


class DuplicateNameError(Exception):
    def __init__(self, duplicates):
        self.duplicates = duplicates


class NoRequirements(Exception):
    pass


class PropertyList(list):
    def _get_template(self):
        return {
            'properties': [],
            'allOf': []
        }


    def _flatten_property_names(self):
        ''' Flatten property and alias names into a single list '''
        for prop in self:
            yield {'name': prop.name, 'type': prop.type, 'desc': prop.description, 'choices': prop.choices}
            for alias in prop.aliases:
                yield {'name': alias, 'type': prop.type, 'desc': prop.description, 'choices': prop.choices}


    def _find_duplicate_names(self):
        ''' Find duplicates to report'''
        props = list(self._flatten_property_names())
        as_set = {p['name'] for p in props}
        if len(as_set) != len(props):
            seen = set()
            repeated = []
            for e in props:
                if e['name'] in seen:
                    repeated.append(e['name'])
                seen.add(e['name'])
            return repeated
        return False


    def get_json_schema_key_values(self, strict=False):
        ''' Generate the actual schema fields to be merged into the parent schema

            Raises `DuplicateNameError` when properties contain duplicate entries
            Raises `NoRequirements` when `strict=True` and the object has 0 required properties
        '''
        duplicates = self._find_duplicate_names()
        if duplicates:
            raise DuplicateNameError(duplicates)

        # Four possible cases here:
        #
        #   1) Required, no aliases
        #   2) Required, aliases
        #   3) Non required, no aliases
        #   4) Non required, aliases
        #

        schema = self._get_template()
        mutexes = []

        for prop in self:
            if prop.aliases:
                all_names = [prop.name] + prop.aliases
                mutex = {
                    'allOf': [{
                        'not': {
                            'required': all_names,
                            'type': 'object'
                        },
                    }]
                }
                if prop.required:
                    mutex['allOf'].append({
                        'oneOf': [
                          {'required': [n], 'type': 'object'}  for n in all_names
                        ]
                    })
                mutexes.append(mutex)

        def _unwrap_type(p):
            if isinstance(p['type'], dict):
                return p['type']
            else:
                base = {'type': p['type'], 'description': p['desc']}
                if p['choices']:
                    if _are_choices_clean(p['choices']):
                        base['enum'] = p['choices']
                    else:
                        logger.warning('Passing `choices`: {} via description'.format(p['choices']))
                        base['description'] += '\n\nPossible choices:\n' + '\n'.join(map(str, p['choices']))
                return base

        schema['properties'] = {
            p['name']: _unwrap_type(p) for p in self._flatten_property_names()
        }

        if mutexes:
            schema['allOf'] = mutexes
        else:
            del schema['allOf']
            req = [p.name for p in self if p.required]
            if req:
                schema['required'] = req
            elif strict:
                raise NoRequirements

        return schema


def _are_choices_clean(choices):
    ''' Sanity check to make sure that there are no extra choices expected '''
    for choice in choices:
        str_choice = str(choice)
        if ' ' in str_choice or '\n' in str_choice:
            return False
    return True


def _find_script_files(path):
    ''' Find all files ending with `.py` in the given directory tree and return them '''
    target_directory = os.path.abspath(path)
    script_files, core_files = [], []

    for root, _, files in os.walk(target_directory):
        for file in files:
            absolute_path = os.path.join(root, file)
            # Skip symlinks so that we don't process the same file more than once
            if os.path.islink(absolute_path):
                continue
            if file.endswith('.py'):
                if '/lib/ansible/modules/core' in absolute_path:
                    core_files.append(absolute_path)
                else:
                    script_files.append(absolute_path)

    return script_files + core_files


def _parse_files(files):
    ''' Parse Python files and return a mapping of `path` => `ast.Module` '''
    parsed_files = OrderedDict()
    for file in files:
        with open(file, 'r') as fp:
            try:
                parsed_files[file] = ast.parse(fp.read(), file)
            except:
                logger.warning('Invalid Python file {}'.format(file))
                continue
    return parsed_files


def _find_documentation_variable(filename, module):
    ''' Extract `DOCUMENTATION` string from the module '''
    for node in ast.iter_child_nodes(module):
        if isinstance(node, ast.Assign) and isinstance(node.targets[0], ast.Name):
            if node.targets[0].id == DOCUMENTATION_KEY:
                # We could probably dig a little but deeper here, this seems to
                # suffice though
                if not isinstance(node.value, ast.Str):
                    logger.warning('Value for {} is not a string but "{}"'.format(
                        filename, type(node.value)))

                try:
                    return yaml.load(node.value.s)
                except yaml.YAMLError:
                    logger.error('Error loading {}'.format(filename))
                    return None


def _infer_type(option, module, name, version):
    ''' Infer JSON schema types from Ansible type description

        returns tuple (required, type_descriptor)
    '''
    default = option.get('default', None)
    description = option.get('description', '')
    if isinstance(description, list):
        description = "\n".join(description)

    type_descriptor = {}

    TYPE_MAP = {
        'int': {'$ref': '#/definitions/ansible_number'},
        'bool': {'$ref': '#/definitions/ansible_truth'},
        'str': 'string',
        'float': 'number',
        'object': 'object',
        'dict': 'object'
    }

    choices = option.get('choices', None)

    type_name = option.get('type', 'str')
    mapped_type = TYPE_MAP.get(type_name, 'string')

    # This is a hack, however there doesn't seem any better way
    # of distinguishing whether the given option is a list option
    # so handle it heuristically
    if LIST_MATCHER.match(description):
        type_descriptor = {'type': 'array', 'items': {'type': mapped_type}}
    elif DICT_MATCHER.match(description):
        type_descriptor = {'type': 'object'}
    else:
        if isinstance(mapped_type, dict):
            type_descriptor = mapped_type
        else:
            type_descriptor = {'type': mapped_type}
            if mapped_type == 'string' and choices:
                type_descriptor['choices'] = choices

    if module in __typefixes:
        module_specific = __typefixes[module]
        if name in module_specific:
            rspec = module_specific[name]
            type_descriptor = apply_fix(rspec, type_descriptor, version)

    if default:
        description = 'Default: ' + str(default) + '\n\n' + description
    type_descriptor['description'] = description

    return (option.get('required', False), type_descriptor)


def _take_key(key_list, obj):
    ''' Iterate over keys in `key_list` and return the first one which
        is present in `obj`, or None
    '''
    for key in key_list:
        if key in obj:
            return obj[key]

    return None


def _check_keys(key_set_list, obj):
    ''' Check if `obj` contains a full `key_set` from `key_set_list` '''
    for key_set in key_set_list:
        if all(key in obj for key in key_set):
            return True

    return False


def _tranform_deferred_schemas(options, version):
    ''' Deferred transformation to handle particular `free_form` commands '''
    schemas = []
    for (filename, contents) in options:
        props, requireds = {}, []
        schema = {'name': {'type': 'string'}, 'args': {
                  'type': 'object', 'properties': props, 'required': requireds}}

        title = _take_key(TITLE_KEYS, contents)
        if title is None:
            logger.warning('No object title for: {}'.format(filename))
            continue

        properties = PropertyList()
        data = contents.get('options') or {}
        for key, value in data.iteritems():
            # `free_form` is only an indicator of the type of command
            # and should not be an actual key to chooser from
            if key == 'free_form':
                continue
            aliases = value.get('aliases', [])
            if isinstance(aliases, str):
                aliases = [aliases]
            required, descriptor = _infer_type(value, title, key, version)
            typ = descriptor['type'] if 'type' in descriptor else descriptor
            choices = descriptor['choices'] if 'choices' in descriptor else None

            properties.append(
                Property(key, descriptor['description'], typ, required, aliases, choices)
            )

            if required:
                requireds.append(key)

        description = contents.get('description', '')
        if isinstance(description, list):
            description = "\n".join(description)

        try:
            schema['args'].update(properties.get_json_schema_key_values())
        except DuplicateNameError as e:
            logger.error(
                'Skipping {} because it contains duplicate property keys:\n{}'.format(filename, e.duplicates)
            )
            continue
        except NoRequirements:
            logger.error(
                'Skipping {} because no properties are required'.format(filename)
            )
            continue

        schema[title] = {'type': 'string'}

        if not requireds:
            del schema['args']['required']

        schemas.append({'type': 'object', 'properties': schema,
                        'required': [title]})

    return schemas


def _transform_options_to_schemas(options, deferred, version):
    ''' Transform Ansible `options` specification into JSON descriptors '''
    schemas = {'name': {'type': 'string'}}
    for (filename, contents) in options:
        if _check_keys(IGNORE_KEYS, contents):
            logger.debug('Ignoring source file: {}'.format(filename))
            continue

        schema = {'type': 'object', 'description': None, 'properties': dict()}

        title = _take_key(TITLE_KEYS, contents)
        if title is None:
            logger.warning('No object title for: {}'.format(filename))
            continue
        elif title in schemas:
            logger.error(
                'Attempting to insert duplicate entry for {} via {}'.format(title, filename))
            continue

        data = contents.get('options') or {}
        if _check_keys(FREE_FORM_KEYS, data) and title not in COMMAND_MODULES:
            logger.warning(
                'Ignoring non-command free form module {}'.format(filename))
            continue

        if title in COMMAND_MODULES:
            deferred.append((filename, contents))
            continue

        properties = PropertyList()
        for key, value in data.iteritems():
            required, descriptor = _infer_type(value, title, key, version)
            aliases = value.get('aliases', [])
            if isinstance(aliases, str):
                aliases = [aliases]
            typ = descriptor['type'] if 'type' in descriptor else descriptor
            choices = descriptor['choices'] if 'choices' in descriptor else None

            properties.append(
                Property(key, descriptor['description'], typ, required, aliases, choices)
            )

        description = contents.get('description', '')
        if isinstance(description, list):
            description = "\n".join(description)

        schema['description'] = description

        try:
            schema.update(properties.get_json_schema_key_values())
        except DuplicateNameError as e:
            logger.error(
                'Skipping {} because it contains duplicate property keys:\n{}'.format(filename, e.duplicates)
            )
            continue
        except NoRequirements:
            logger.error(
                'Skipping {} because no properties are required'.format(filename)
            )
            continue

        schemas[title] = schema

    return schemas


def _parse_arguments():
    description = ('Generate JSON schema for language servers from Ansible module' +
                   ' documentation in an Ansible repository checkout `target_path`')
    ap = argparse.ArgumentParser(
        prog='ansible-schema-generator', description=description)
    ap.add_argument('-o', '--output-file', default=None,
                    help='write result to this file')
    ap.add_argument('-l', '--log-level',
                    choices=['debug', 'warning', 'error'], default='warning', help='set log level')
    ap.add_argument('-d', '--description', default='Auto-Generated', help='Description string to add to the schema')
    ap.add_argument('-t', '--title', default='Ansible', help='Title of the schema')
    ap.add_argument('-v', '--version', default='2.5.0', help='Version of Ansible for which schemas are generated')
    ap.add_argument(
        'target_path', help='scan this directory for Ansible modules')

    return ap.parse_args()


def main():
    arguments = _parse_arguments()
    target_path = arguments.target_path
    log_level = LOG_LEVEL_MAP[arguments.log_level]

    daiquiri.setup(level=log_level, program_name='ansible-schema')

    logger.debug('Loading modules from: {}'.format(
        os.path.abspath(target_path)))

    # determine where we should write the resulting data
    fp = sys.stdout
    if arguments.output_file:
        logger.debug('Setting output file to: {}'.format(
            os.path.abspath(arguments.output_file)))
        fp = open(arguments.output_file, 'w')

    # find python files and get their AST
    script_files = _find_script_files(target_path)
    parsed_files = _parse_files(script_files)

    # extract data from AST
    collected_data = []
    for filename, module in parsed_files.iteritems():
        variable_value = _find_documentation_variable(filename, module)
        if variable_value:
            collected_data.append((filename, variable_value))

    logger.debug('Transforming {} documents'.format(len(collected_data)))

    deferred = []
    transformed = _transform_options_to_schemas(collected_data, deferred, arguments.version)

    logger.debug('Handing {} deferred schemas'.format(len(deferred)))
    transformed_deferred = _tranform_deferred_schemas(deferred, arguments.version)

    combined = {'anyOf': transformed_deferred + [{'type': 'object',
                                                  'properties': transformed, 'required': ['name']}]}

    output_schemas = {'$schema': 'http://json-schema.org/draft-04/schema#',
                      'type': 'array', 'items': combined,
                      'description': arguments.description,
                      'title': arguments.title,
                      'definitions': get_definitions(),
                      '$contact': {
                          'issues': 'https://github.com/shaded-enmity/ansible-schema-generator/issues',
                          'name': 'Pavel Odvody'
                      }}

    logger.debug('Transformation done!')
    logger.debug('Writing output')

    with fp:
        json.dump(output_schemas, fp, indent=3)

    logger.debug('Done')


if __name__ == '__main__':
    main()
